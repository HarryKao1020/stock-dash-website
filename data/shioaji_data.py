"""
Shioaji API è³‡æ–™è™•ç†æ¨¡çµ„
ç”¨æ–¼å–å¾—å°è‚¡åŠ æ¬ŠæŒ‡æ•¸å’Œæ«ƒè²·æŒ‡æ•¸çš„å³æ™‚è³‡æ–™
"""

import pandas as pd
import numpy as np
import talib
from datetime import datetime, date
from pathlib import Path
import pickle


# å¿«å–ç›®éŒ„è¨­å®š
CACHE_DIR = Path(__file__).parent / "cache" / "shioaji"
CACHE_DIR.mkdir(parents=True, exist_ok=True)


def get_index_with_macd(api, index_type="TSE", start="2024-10-01", end="2025-12-01"):
    """
    å–å¾—æŒ‡æ•¸æ—¥ç·š + MACD + å‡ç·š
    """
    # é¸æ“‡åˆç´„
    contract = (
        api.Contracts.Indexs.TSE.TSE001
        if index_type == "TSE"
        else api.Contracts.Indexs.OTC.OTC101
    )

    # å–å¾—ä¸¦è™•ç†è³‡æ–™
    kbars = api.kbars(contract=contract, start=start, end=end)
    df = pd.DataFrame(kbars.model_dump())
    df["ts"] = pd.to_datetime(df["ts"])
    df["date"] = df["ts"].dt.date

    # è½‰æ—¥ç·š
    daily = df.groupby("date").agg(
        {"Open": "first", "High": "max", "Low": "min", "Close": "last", "Amount": "sum"}
    )

    daily.index = pd.to_datetime(daily.index)
    daily["Volume"] = daily["Amount"] / 1e8

    # è¨ˆç®— MACD
    daily["DIF"], daily["MACD"], daily["MACD_Hist"] = talib.MACD(
        daily["Close"].values, fastperiod=12, slowperiod=26, signalperiod=9
    )

    # è¨ˆç®—å‡ç·š
    daily["ma5"] = daily["Close"].rolling(window=5).mean().round(2)
    daily["ma20"] = daily["Close"].rolling(window=20).mean().round(2)
    daily["ma60"] = daily["Close"].rolling(window=60).mean().round(2)
    daily["ma120"] = daily["Close"].rolling(window=120).mean().round(2)

    return daily[
        [
            "Open",
            "High",
            "Low",
            "Close",
            "Volume",
            "DIF",
            "MACD",
            "MACD_Hist",
            "ma5",
            "ma20",
            "ma60",
            "ma120",
        ]
    ]


def update_both_indexes_realtime(tse_df, otc_df, api, use_cache=True):
    """
    åŒæ™‚æ›´æ–° TSE å’Œ OTC (1åˆ†é˜æ›´æ–°å„ªåŒ–ç‰ˆ) + å‡ç·šè¨ˆç®—
    """

    contracts = [api.Contracts.Indexs.TSE.TSE001, api.Contracts.Indexs.OTC.OTC101]

    try:
        snapshots = api.snapshots(contracts)
    except Exception as e:
        print(f"API å‘¼å«å¤±æ•—: {e}")
        return tse_df, otc_df

    def update_single_df(daily_df, snapshot):
        today = pd.Timestamp(datetime.fromtimestamp(snapshot.ts / 1e9).date())

        # æª¢æŸ¥æ˜¯å¦ç‚ºæ–°çš„ä¸€å¤©
        is_new_day = today not in daily_df.index

        if is_new_day:
            # æ–°å¢ç•¶å¤©è³‡æ–™
            daily_df.loc[today] = {
                "Open": snapshot.open,
                "High": snapshot.high,
                "Low": snapshot.low,
                "Close": snapshot.close,
                "Volume": snapshot.total_amount / 1e8,
                "Amount": snapshot.total_amount,
                "DIF": np.nan,
                "MACD": np.nan,
                "MACD_Hist": np.nan,
                "ma5": np.nan,
                "ma20": np.nan,
                "ma60": np.nan,
                "ma120": np.nan,
            }
        else:
            # æ›´æ–°ç•¶å¤©è³‡æ–™
            daily_df.loc[today, "Open"] = snapshot.open
            daily_df.loc[today, "High"] = max(
                daily_df.loc[today, "High"], snapshot.high
            )
            daily_df.loc[today, "Low"] = min(daily_df.loc[today, "Low"], snapshot.low)
            daily_df.loc[today, "Close"] = snapshot.close
            daily_df.loc[today, "Volume"] = snapshot.total_amount / 1e8

        # è¨ˆç®— MACD - åªå–å¿…è¦çš„è³‡æ–™é•·åº¦
        window_size = 50
        if len(daily_df) >= window_size:
            recent_data = daily_df.tail(window_size)
        else:
            recent_data = daily_df

        macd_dif, macd_signal, macd_hist = talib.MACD(
            recent_data["Close"].values, fastperiod=12, slowperiod=26, signalperiod=9
        )

        # åªæ›´æ–°ä»Šå¤©çš„ MACD å€¼
        if not np.isnan(macd_dif[-1]):
            daily_df.loc[today, "DIF"] = macd_dif[-1]
            daily_df.loc[today, "MACD"] = macd_signal[-1]
            daily_df.loc[today, "MACD_Hist"] = macd_hist[-1]

        # è¨ˆç®—å‡ç·š - ä½¿ç”¨ rolling æ–¹å¼æ›´æœ‰æ•ˆç‡
        # ma5
        if len(daily_df) >= 5:
            ma5_window = daily_df["Close"].tail(5)
            daily_df.loc[today, "ma5"] = ma5_window.mean()

        # ma20
        if len(daily_df) >= 20:
            ma20_window = daily_df["Close"].tail(20)
            daily_df.loc[today, "ma20"] = ma20_window.mean()

        # ma60
        if len(daily_df) >= 60:
            ma60_window = daily_df["Close"].tail(60)
            daily_df.loc[today, "ma60"] = ma60_window.mean()

        # ma120
        if len(daily_df) >= 120:
            ma120_window = daily_df["Close"].tail(120)
            daily_df.loc[today, "ma120"] = ma120_window.mean()

        return daily_df

    tse_df = update_single_df(tse_df, snapshots[0])
    otc_df = update_single_df(otc_df, snapshots[1])

    return tse_df, otc_df


def _get_cache_path(index_type):
    """å–å¾—å¿«å–æª”æ¡ˆè·¯å¾‘"""
    return CACHE_DIR / f"{index_type}_historical.pkl"


def _save_to_cache(df, index_type):
    """å„²å­˜æ­·å²è³‡æ–™åˆ°å¿«å–æª”æ¡ˆ"""
    try:
        cache_path = _get_cache_path(index_type)
        # åªå„²å­˜ä»Šå¤©ä¹‹å‰çš„è³‡æ–™
        today = pd.Timestamp.now().normalize()
        historical_df = df[df.index < today].copy()

        with open(cache_path, "wb") as f:
            pickle.dump(historical_df, f)

        print(
            f"âœ… {index_type} æ­·å²è³‡æ–™å·²å„²å­˜åˆ°å¿«å– (æˆªè‡³ {historical_df.index.max().date()})"
        )
        return True
    except Exception as e:
        print(f"âš ï¸ å„²å­˜å¿«å–å¤±æ•—: {e}")
        return False


def _load_from_cache(index_type):
    """å¾å¿«å–æª”æ¡ˆè¼‰å…¥æ­·å²è³‡æ–™"""
    try:
        cache_path = _get_cache_path(index_type)

        if not cache_path.exists():
            print(f"ğŸ“‚ æ‰¾ä¸åˆ° {index_type} çš„å¿«å–æª”æ¡ˆ")
            return None

        with open(cache_path, "rb") as f:
            df = pickle.load(f)

        print(f"âœ… å¾å¿«å–è¼‰å…¥ {index_type} æ­·å²è³‡æ–™ (æˆªè‡³ {df.index.max().date()})")
        return df
    except Exception as e:
        print(f"âš ï¸ è¼‰å…¥å¿«å–å¤±æ•—: {e}")
        return None


def _need_update_historical(cached_df):
    """æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ­·å²è³‡æ–™"""
    if cached_df is None:
        return True

    # æª¢æŸ¥å¿«å–çš„æœ€å¾Œæ—¥æœŸ
    last_date = cached_df.index.max()
    yesterday = pd.Timestamp.now().normalize() - pd.Timedelta(days=1)

    # å¦‚æœå¿«å–è³‡æ–™åˆ°æ˜¨å¤©,å°±ä¸ç”¨æ›´æ–°
    if last_date >= yesterday:
        print(f"ğŸ“Š æ­·å²è³‡æ–™å·²æ˜¯æœ€æ–° (æˆªè‡³ {last_date.date()})")
        return False

    print(f"ğŸ”„ æ­·å²è³‡æ–™éœ€è¦æ›´æ–° (å¿«å–: {last_date.date()}, éœ€è¦åˆ°: {yesterday.date()})")
    return True


def get_index_data_smart(
    api, index_type="TSE", start="2024-01-01", force_refresh=False
):
    """
    æ™ºæ…§å–å¾—æŒ‡æ•¸è³‡æ–™ (ä½¿ç”¨å¿«å–å„ªåŒ–)

    ç­–ç•¥:
    1. è¼‰å…¥å¿«å–çš„æ­·å²è³‡æ–™ (ä»Šå¤©ä¹‹å‰)
    2. åªå‘ API è«‹æ±‚ç¼ºå°‘çš„æ—¥æœŸ
    3. åˆä½µè³‡æ–™ä¸¦æ›´æ–°å¿«å–
    4. ç”¨ snapshot æ›´æ–°ä»Šå¤©çš„å³æ™‚è³‡æ–™

    Args:
        api: Shioaji API å¯¦ä¾‹
        index_type: 'TSE' æˆ– 'OTC'
        start: é–‹å§‹æ—¥æœŸ
        force_refresh: å¼·åˆ¶é‡æ–°ä¸‹è¼‰æ‰€æœ‰è³‡æ–™

    Returns:
        DataFrame: åŒ…å«å®Œæ•´è³‡æ–™ (åŒ…æ‹¬ä»Šå¤©)
    """
    today = pd.Timestamp.now().normalize()
    yesterday = today - pd.Timedelta(days=1)

    # 1. å˜—è©¦è¼‰å…¥å¿«å–
    cached_df = None if force_refresh else _load_from_cache(index_type)

    # 2. æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ­·å²è³‡æ–™
    if cached_df is None or _need_update_historical(cached_df):
        # éœ€è¦ä¸‹è¼‰æ­·å²è³‡æ–™
        if cached_df is None:
            # å®Œå…¨æ²’æœ‰å¿«å–,ä¸‹è¼‰å…¨éƒ¨
            print(
                f"ğŸ“¥ ä¸‹è¼‰ {index_type} å®Œæ•´æ­·å²è³‡æ–™ ({start} ~ {yesterday.date()})..."
            )
            historical_df = get_index_with_macd(
                api,
                index_type=index_type,
                start=start,
                end=yesterday.strftime("%Y-%m-%d"),
            )
        else:
            # æœ‰å¿«å–,åªä¸‹è¼‰ç¼ºå°‘çš„éƒ¨åˆ†
            last_cached_date = cached_df.index.max()
            next_day = (last_cached_date + pd.Timedelta(days=1)).strftime("%Y-%m-%d")

            print(f"ğŸ“¥ ä¸‹è¼‰ {index_type} å¢é‡è³‡æ–™ ({next_day} ~ {yesterday.date()})...")

            try:
                new_data = get_index_with_macd(
                    api,
                    index_type=index_type,
                    start=next_day,
                    end=yesterday.strftime("%Y-%m-%d"),
                )

                # åˆä½µèˆŠè³‡æ–™å’Œæ–°è³‡æ–™
                historical_df = pd.concat([cached_df, new_data])
                historical_df = historical_df[
                    ~historical_df.index.duplicated(keep="last")
                ]
                historical_df = historical_df.sort_index()

                # é‡æ–°è¨ˆç®—å‡ç·š (å› ç‚ºæ–°å¢è³‡æ–™å¾Œå‡ç·šæœƒæ”¹è®Š)
                historical_df["ma5"] = (
                    historical_df["Close"].rolling(window=5).mean().round(2)
                )
                historical_df["ma20"] = (
                    historical_df["Close"].rolling(window=20).mean().round(2)
                )
                historical_df["ma60"] = (
                    historical_df["Close"].rolling(window=60).mean().round(2)
                )
                historical_df["ma120"] = (
                    historical_df["Close"].rolling(window=120).mean().round(2)
                )

                print(f"âœ… åˆä½µå®Œæˆ: å…± {len(historical_df)} ç­†è³‡æ–™")

            except Exception as e:
                print(f"âš ï¸ å¢é‡æ›´æ–°å¤±æ•—,ä½¿ç”¨å¿«å–è³‡æ–™: {e}")
                historical_df = cached_df

        # å„²å­˜åˆ°å¿«å–
        _save_to_cache(historical_df, index_type)
    else:
        # å¿«å–è³‡æ–™å·²æ˜¯æœ€æ–°
        historical_df = cached_df

    # 3. æ›´æ–°ä»Šå¤©çš„å³æ™‚è³‡æ–™
    print(f"ğŸ“¡ å–å¾— {index_type} ä»Šæ—¥å³æ™‚è³‡æ–™...")

    try:
        contract = (
            api.Contracts.Indexs.TSE.TSE001
            if index_type == "TSE"
            else api.Contracts.Indexs.OTC.OTC101
        )
        snapshot = api.snapshots([contract])[0]

        # æª¢æŸ¥ä»Šå¤©æ˜¯å¦å·²æœ‰è³‡æ–™
        if today in historical_df.index:
            # æ›´æ–°ä»Šå¤©çš„è³‡æ–™
            historical_df.loc[today, "Open"] = snapshot.open
            historical_df.loc[today, "High"] = max(
                historical_df.loc[today, "High"], snapshot.high
            )
            historical_df.loc[today, "Low"] = min(
                historical_df.loc[today, "Low"], snapshot.low
            )
            historical_df.loc[today, "Close"] = snapshot.close
            historical_df.loc[today, "Volume"] = snapshot.total_amount / 1e8
        else:
            # æ–°å¢ä»Šå¤©çš„è³‡æ–™
            today_data = pd.Series(
                {
                    "Open": snapshot.open,
                    "High": snapshot.high,
                    "Low": snapshot.low,
                    "Close": snapshot.close,
                    "Volume": snapshot.total_amount / 1e8,
                    "DIF": np.nan,
                    "MACD": np.nan,
                    "MACD_Hist": np.nan,
                    "ma5": np.nan,
                    "ma20": np.nan,
                    "ma60": np.nan,
                    "ma120": np.nan,
                },
                name=today,
            )

            historical_df = pd.concat([historical_df, today_data.to_frame().T])

        # é‡æ–°è¨ˆç®—ä»Šå¤©çš„ MACD å’Œå‡ç·š
        window_size = 50
        recent_data = historical_df.tail(window_size)

        macd_dif, macd_signal, macd_hist = talib.MACD(
            recent_data["Close"].values, fastperiod=12, slowperiod=26, signalperiod=9
        )

        if not np.isnan(macd_dif[-1]):
            historical_df.loc[today, "DIF"] = macd_dif[-1]
            historical_df.loc[today, "MACD"] = macd_signal[-1]
            historical_df.loc[today, "MACD_Hist"] = macd_hist[-1]

        # è¨ˆç®—å‡ç·š
        if len(historical_df) >= 5:
            historical_df.loc[today, "ma5"] = historical_df["Close"].tail(5).mean()
        if len(historical_df) >= 20:
            historical_df.loc[today, "ma20"] = historical_df["Close"].tail(20).mean()
        if len(historical_df) >= 60:
            historical_df.loc[today, "ma60"] = historical_df["Close"].tail(60).mean()
        if len(historical_df) >= 120:
            historical_df.loc[today, "ma120"] = historical_df["Close"].tail(120).mean()

        print(f"âœ… {index_type} å³æ™‚è³‡æ–™æ›´æ–°å®Œæˆ (æ”¶ç›¤: {snapshot.close:.2f})")

    except Exception as e:
        print(f"âš ï¸ å³æ™‚è³‡æ–™æ›´æ–°å¤±æ•—: {e}")

    return historical_df


# å…¨åŸŸè®Šæ•¸ç”¨æ–¼å¿«å–è³‡æ–™
_tse_cache = None
_otc_cache = None
_last_update = None


def get_cached_or_fetch(api, force_refresh=False, realtime_update=True):
    """
    å–å¾—å¿«å–çš„è³‡æ–™æˆ–é‡æ–°æŠ“å– (æ”¹é€²ç‰ˆ,ä½¿ç”¨æª”æ¡ˆå¿«å–)

    Args:
        api: Shioaji API å¯¦ä¾‹
        force_refresh: æ˜¯å¦å¼·åˆ¶é‡æ–°æŠ“å–æ­·å²è³‡æ–™
        realtime_update: æ˜¯å¦æ¯æ¬¡éƒ½æ›´æ–°å³æ™‚è³‡æ–™ (é è¨­ True)

    Returns:
        tuple: (tse_df, otc_df)
    """
    global _tse_cache, _otc_cache, _last_update

    now = datetime.now()

    # æª¢æŸ¥æ­·å²è³‡æ–™å¿«å–æ˜¯å¦éœ€è¦æ›´æ–° (æ¯ 1 å°æ™‚æª¢æŸ¥ä¸€æ¬¡)
    need_historical_update = (
        _tse_cache is None
        or _otc_cache is None
        or force_refresh
        or _last_update is None
        or (now - _last_update).seconds > 3600  # 1 å°æ™‚
    )

    if need_historical_update:
        print("=" * 60)
        print("ğŸ”„ æ›´æ–°æ­·å²è³‡æ–™...")
        print("=" * 60)

        # ä½¿ç”¨æ™ºæ…§å¿«å–æ©Ÿåˆ¶ (è¼‰å…¥æ­·å²è³‡æ–™)
        _tse_cache = get_index_data_smart(api, "TSE", force_refresh=force_refresh)
        _otc_cache = get_index_data_smart(api, "OTC", force_refresh=force_refresh)
        _last_update = now

        print("=" * 60)
        print(f"âœ… æ­·å²è³‡æ–™æ›´æ–°å®Œæˆ! æœ€å¾Œæ›´æ–°æ™‚é–“: {now.strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)

    # å¦‚æœå•Ÿç”¨å³æ™‚æ›´æ–°,æ¯æ¬¡éƒ½æ›´æ–°ä»Šå¤©çš„è³‡æ–™
    if realtime_update:
        print(f"ğŸ“¡ æ›´æ–°å³æ™‚è³‡æ–™... ({now.strftime('%H:%M:%S')})")

        try:
            # å–å¾—å³æ™‚ snapshot
            tse_contract = api.Contracts.Indexs.TSE.TSE001
            otc_contract = api.Contracts.Indexs.OTC.OTC101
            snapshots = api.snapshots([tse_contract, otc_contract])

            today = pd.Timestamp.now().normalize()

            # æ›´æ–° TSE
            tse_snapshot = snapshots[0]
            if today in _tse_cache.index:
                _tse_cache.loc[today, "Open"] = tse_snapshot.open
                _tse_cache.loc[today, "High"] = max(
                    _tse_cache.loc[today, "High"], tse_snapshot.high
                )
                _tse_cache.loc[today, "Low"] = min(
                    _tse_cache.loc[today, "Low"], tse_snapshot.low
                )
                _tse_cache.loc[today, "Close"] = tse_snapshot.close
                _tse_cache.loc[today, "Volume"] = tse_snapshot.total_amount / 1e8
            else:
                # æ–°å¢ä»Šå¤©çš„è³‡æ–™
                _tse_cache.loc[today] = {
                    "Open": tse_snapshot.open,
                    "High": tse_snapshot.high,
                    "Low": tse_snapshot.low,
                    "Close": tse_snapshot.close,
                    "Volume": tse_snapshot.total_amount / 1e8,
                    "DIF": np.nan,
                    "MACD": np.nan,
                    "MACD_Hist": np.nan,
                    "ma5": np.nan,
                    "ma20": np.nan,
                    "ma60": np.nan,
                    "ma120": np.nan,
                }

            # é‡æ–°è¨ˆç®— TSE ä»Šå¤©çš„æŒ‡æ¨™
            _recalculate_indicators(_tse_cache, today)

            # æ›´æ–° OTC
            otc_snapshot = snapshots[1]
            if today in _otc_cache.index:
                _otc_cache.loc[today, "Open"] = otc_snapshot.open
                _otc_cache.loc[today, "High"] = max(
                    _otc_cache.loc[today, "High"], otc_snapshot.high
                )
                _otc_cache.loc[today, "Low"] = min(
                    _otc_cache.loc[today, "Low"], otc_snapshot.low
                )
                _otc_cache.loc[today, "Close"] = otc_snapshot.close
                _otc_cache.loc[today, "Volume"] = otc_snapshot.total_amount / 1e8
            else:
                # æ–°å¢ä»Šå¤©çš„è³‡æ–™
                _otc_cache.loc[today] = {
                    "Open": otc_snapshot.open,
                    "High": otc_snapshot.high,
                    "Low": otc_snapshot.low,
                    "Close": otc_snapshot.close,
                    "Volume": otc_snapshot.total_amount / 1e8,
                    "DIF": np.nan,
                    "MACD": np.nan,
                    "MACD_Hist": np.nan,
                    "ma5": np.nan,
                    "ma20": np.nan,
                    "ma60": np.nan,
                    "ma120": np.nan,
                }

            # é‡æ–°è¨ˆç®— OTC ä»Šå¤©çš„æŒ‡æ¨™
            _recalculate_indicators(_otc_cache, today)

            print(
                f"âœ… å³æ™‚è³‡æ–™æ›´æ–°å®Œæˆ - TSE: {tse_snapshot.close:.2f}, OTC: {otc_snapshot.close:.2f}"
            )

        except Exception as e:
            print(f"âš ï¸ å³æ™‚è³‡æ–™æ›´æ–°å¤±æ•—: {e}")
    else:
        print(
            f"â„¹ï¸ ä½¿ç”¨å¿«å–è³‡æ–™ (ä¸Šæ¬¡æ›´æ–°: {_last_update.strftime('%H:%M:%S') if _last_update else 'N/A'})"
        )

    return _tse_cache.copy(), _otc_cache.copy()


def _recalculate_indicators(df, today):
    """é‡æ–°è¨ˆç®—ä»Šå¤©çš„æŠ€è¡“æŒ‡æ¨™ (MACD å’Œå‡ç·š)"""
    import talib

    # è¨ˆç®— MACD (ä½¿ç”¨æœ€è¿‘ 50 ç­†)
    window_size = min(50, len(df))
    recent_data = df.tail(window_size)

    macd_dif, macd_signal, macd_hist = talib.MACD(
        recent_data["Close"].values, fastperiod=12, slowperiod=26, signalperiod=9
    )

    if not np.isnan(macd_dif[-1]):
        df.loc[today, "DIF"] = macd_dif[-1]
        df.loc[today, "MACD"] = macd_signal[-1]
        df.loc[today, "MACD_Hist"] = macd_hist[-1]

    # è¨ˆç®—å‡ç·š
    if len(df) >= 5:
        df.loc[today, "ma5"] = df["Close"].tail(5).mean()
    if len(df) >= 20:
        df.loc[today, "ma20"] = df["Close"].tail(20).mean()
    if len(df) >= 60:
        df.loc[today, "ma60"] = df["Close"].tail(60).mean()
    if len(df) >= 120:
        df.loc[today, "ma120"] = df["Close"].tail(120).mean()


def clear_cache():
    """æ¸…é™¤æ‰€æœ‰å¿«å– (åŒ…æ‹¬æª”æ¡ˆå’Œè¨˜æ†¶é«”)"""
    global _tse_cache, _otc_cache, _last_update

    # æ¸…é™¤è¨˜æ†¶é«”å¿«å–
    _tse_cache = None
    _otc_cache = None
    _last_update = None

    # æ¸…é™¤æª”æ¡ˆå¿«å–
    for cache_file in CACHE_DIR.glob("*.pkl"):
        try:
            cache_file.unlink()
            print(f"ğŸ—‘ï¸ å·²åˆªé™¤å¿«å–æª”æ¡ˆ: {cache_file.name}")
        except Exception as e:
            print(f"âš ï¸ åˆªé™¤å¿«å–å¤±æ•— {cache_file.name}: {e}")

    print("âœ… å¿«å–å·²æ¸…é™¤")


# å…¨åŸŸè®Šæ•¸ç”¨æ–¼å¿«å–è³‡æ–™ (èˆŠç‰ˆç›¸å®¹)
_tse_cache = None
_otc_cache = None
_last_update = None


def get_cached_or_fetch_old(api, force_refresh=False):
    """
    å–å¾—å¿«å–çš„è³‡æ–™æˆ–é‡æ–°æŠ“å– (èˆŠç‰ˆ,åƒ…è¨˜æ†¶é«”å¿«å–)

    ä¿ç•™æ­¤å‡½æ•¸ä»¥ç¶­æŒå‘å¾Œç›¸å®¹æ€§
    å»ºè­°ä½¿ç”¨æ–°çš„ get_cached_or_fetch() å‡½æ•¸

    Args:
        api: Shioaji API å¯¦ä¾‹
        force_refresh: æ˜¯å¦å¼·åˆ¶é‡æ–°æŠ“å–

    Returns:
        tuple: (tse_df, otc_df)
    """
    global _tse_cache, _otc_cache, _last_update

    now = datetime.now()

    # å¦‚æœæ²’æœ‰å¿«å–æˆ–è¶…é 1 å°æ™‚ï¼Œæˆ–å¼·åˆ¶æ›´æ–°
    if (
        _tse_cache is None
        or _otc_cache is None
        or force_refresh
        or (_last_update and (now - _last_update).seconds > 3600)
    ):

        print("ğŸ”„ é‡æ–°æŠ“å–æ­·å²è³‡æ–™...")
        _tse_cache = get_index_with_macd(api, "TSE", "2024-01-01", "2025-12-01")
        _otc_cache = get_index_with_macd(api, "OTC", "2024-01-01", "2025-12-01")
        _last_update = now
        print("âœ… æ­·å²è³‡æ–™è¼‰å…¥å®Œæˆ")

    # æ›´æ–°å³æ™‚è³‡æ–™
    print("ğŸ“¡ æ›´æ–°å³æ™‚è³‡æ–™...")
    tse_updated, otc_updated = update_both_indexes_realtime(_tse_cache, _otc_cache, api)

    return tse_updated, otc_updated
