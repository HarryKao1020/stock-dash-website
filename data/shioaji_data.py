"""
Shioaji API è³‡æ–™è™•ç†æ¨¡çµ„ - å„ªåŒ–ç‰ˆ
æ”¹é€²ï¼š
1. æ›´è°æ˜çš„å¿«å–é‚è¼¯ï¼ˆé¿å…é‡è¤‡è¨ˆç®—ï¼‰
2. å³æ™‚è³‡æ–™æœ‰ç¨ç«‹çš„æ›´æ–°é–“éš”ï¼ˆé è¨­ 60 ç§’ï¼‰
3. åªåœ¨è³‡æ–™çœŸæ­£è®ŠåŒ–æ™‚æ‰é‡æ–°è¨ˆç®—æŒ‡æ¨™
"""

import pandas as pd
import numpy as np
import talib
from datetime import datetime, date
from pathlib import Path
import pickle
from finlab import data
import sys
import time
import threading

# åŒ¯å…¥å…±ç”¨å‡½æ•¸
sys.path.insert(0, str(Path(__file__).parent.parent))
from finlab_data import get_cache_dir

# å¿«å–ç›®éŒ„
CACHE_DIR = get_cache_dir("shioaji")

# ============================================
# ğŸ†• å…¨åŸŸå¿«å–è®Šæ•¸
# ============================================
_tse_cache = None
_otc_cache = None
_last_historical_update = None  # æ­·å²è³‡æ–™ä¸Šæ¬¡æ›´æ–°æ™‚é–“
_last_realtime_update = None  # å³æ™‚è³‡æ–™ä¸Šæ¬¡æ›´æ–°æ™‚é–“
_cache_lock = threading.Lock()

# ğŸ†• å¿«å–è¨­å®š
HISTORICAL_UPDATE_INTERVAL = 3600  # æ­·å²è³‡æ–™æ›´æ–°é–“éš”ï¼ˆç§’ï¼‰= 1 å°æ™‚
REALTIME_UPDATE_INTERVAL = 60  # å³æ™‚è³‡æ–™æ›´æ–°é–“éš”ï¼ˆç§’ï¼‰= 1 åˆ†é˜


def get_transaction_amount_from_finlab():
    """å¾ FinLab å–å¾—æ­·å²æˆäº¤é‡‘é¡è³‡æ–™"""
    try:
        print("ğŸ“¥ å¾ FinLab å–å¾—æˆäº¤é‡‘é¡è³‡æ–™...")
        money = data.get("market_transaction_info:æˆäº¤é‡‘é¡")
        result = pd.DataFrame(
            {"TSE_Amount": money["TAIEX"] / 1e8, "OTC_Amount": money["OTC"] / 1e8}
        )
        result = result[result.index.dayofweek < 5]
        result = result.dropna()
        print(f"âœ… FinLab æˆäº¤é‡‘é¡è³‡æ–™è¼‰å…¥å®Œæˆ (æˆªè‡³ {result.index.max().date()})")
        return result
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•å¾ FinLab å–å¾—æˆäº¤é‡‘é¡: {e}")
        return None


def _recalculate_all_indicators(df):
    """é‡æ–°è¨ˆç®—æ•´å€‹ DataFrame çš„æ‰€æœ‰æŠ€è¡“æŒ‡æ¨™"""
    df = df.copy()
    df["DIF"], df["MACD"], df["MACD_Hist"] = talib.MACD(
        df["Close"].values, fastperiod=12, slowperiod=26, signalperiod=9
    )
    df["ma5"] = df["Close"].rolling(window=5).mean().round(2)
    df["ma20"] = df["Close"].rolling(window=20).mean().round(2)
    df["ma60"] = df["Close"].rolling(window=60).mean().round(2)
    df["ma120"] = df["Close"].rolling(window=120).mean().round(2)
    return df


def _recalculate_today_only(df, today):
    """
    ğŸ†• åªé‡æ–°è¨ˆç®—ä»Šå¤©çš„æŒ‡æ¨™ï¼ˆæ¯”é‡ç®—æ•´å€‹ DataFrame å¿«å¾ˆå¤šï¼‰
    """
    # MACD - åªç”¨æœ€è¿‘ 50 ç­†è¨ˆç®—
    window_size = min(50, len(df))
    recent_close = df["Close"].tail(window_size).values

    macd_dif, macd_signal, macd_hist = talib.MACD(
        recent_close, fastperiod=12, slowperiod=26, signalperiod=9
    )

    if len(macd_dif) > 0 and not np.isnan(macd_dif[-1]):
        df.loc[today, "DIF"] = macd_dif[-1]
        df.loc[today, "MACD"] = macd_signal[-1]
        df.loc[today, "MACD_Hist"] = macd_hist[-1]

    # å‡ç·š - åªè¨ˆç®—ä»Šå¤©çš„å€¼
    if len(df) >= 5:
        df.loc[today, "ma5"] = df["Close"].tail(5).mean().round(2)
    if len(df) >= 20:
        df.loc[today, "ma20"] = df["Close"].tail(20).mean().round(2)
    if len(df) >= 60:
        df.loc[today, "ma60"] = df["Close"].tail(60).mean().round(2)
    if len(df) >= 120:
        df.loc[today, "ma120"] = df["Close"].tail(120).mean().round(2)

    return df


def get_index_with_macd(api, index_type="TSE", start="2024-10-01", end="2025-12-01"):
    """å–å¾—æŒ‡æ•¸æ—¥ç·š + MACD + å‡ç·š"""
    contract = (
        api.Contracts.Indexs.TSE.TSE001
        if index_type == "TSE"
        else api.Contracts.Indexs.OTC.OTC101
    )

    kbars = api.kbars(contract=contract, start=start, end=end)
    df = pd.DataFrame(kbars.model_dump())
    df["ts"] = pd.to_datetime(df["ts"])
    df["date"] = df["ts"].dt.date

    daily = df.groupby("date").agg(
        {"Open": "first", "High": "max", "Low": "min", "Close": "last", "Amount": "sum"}
    )

    daily.index = pd.to_datetime(daily.index)
    daily["Amount"] = daily["Amount"] / 1e8

    # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
    daily = _recalculate_all_indicators(daily)

    # éæ¿¾é€±æœ«
    daily = daily[daily.index.dayofweek < 5]
    daily = daily.dropna(subset=["Open", "High", "Low", "Close"])

    return daily[
        [
            "Open",
            "High",
            "Low",
            "Close",
            "Amount",
            "DIF",
            "MACD",
            "MACD_Hist",
            "ma5",
            "ma20",
            "ma60",
            "ma120",
        ]
    ]


def _get_cache_path(index_type):
    return CACHE_DIR / f"{index_type}_historical.pkl"


def _save_to_cache(df, index_type):
    try:
        cache_path = _get_cache_path(index_type)
        today = pd.Timestamp.now().normalize()
        historical_df = df[df.index < today].copy()
        with open(cache_path, "wb") as f:
            pickle.dump(historical_df, f)
        print(f"âœ… {index_type} æ­·å²è³‡æ–™å·²å„²å­˜åˆ°å¿«å–")
        return True
    except Exception as e:
        print(f"âš ï¸ å„²å­˜å¿«å–å¤±æ•—: {e}")
        return False


def _load_from_cache(index_type):
    try:
        cache_path = _get_cache_path(index_type)
        if not cache_path.exists():
            return None
        with open(cache_path, "rb") as f:
            df = pickle.load(f)
        print(f"âœ… å¾å¿«å–è¼‰å…¥ {index_type} æ­·å²è³‡æ–™ (æˆªè‡³ {df.index.max().date()})")
        return df
    except Exception as e:
        print(f"âš ï¸ è¼‰å…¥å¿«å–å¤±æ•—: {e}")
        return None


def _need_update_historical(cached_df):
    if cached_df is None:
        return True
    last_date = cached_df.index.max()
    yesterday = pd.Timestamp.now().normalize() - pd.Timedelta(days=1)
    return last_date < yesterday


def get_index_data_smart(
    api, index_type="TSE", start="2024-01-01", force_refresh=False
):
    """æ™ºæ…§å–å¾—æŒ‡æ•¸è³‡æ–™ï¼ˆä½¿ç”¨å¿«å–å„ªåŒ–ï¼‰"""
    today = pd.Timestamp.now().normalize()
    yesterday = today - pd.Timedelta(days=1)

    cached_df = None if force_refresh else _load_from_cache(index_type)
    finlab_amount = get_transaction_amount_from_finlab()

    if cached_df is None or _need_update_historical(cached_df):
        if cached_df is None:
            print(f"ğŸ“¥ ä¸‹è¼‰ {index_type} å®Œæ•´æ­·å²è³‡æ–™...")
            historical_df = get_index_with_macd(
                api,
                index_type=index_type,
                start=start,
                end=yesterday.strftime("%Y-%m-%d"),
            )
        else:
            last_cached_date = cached_df.index.max()
            next_day = (last_cached_date + pd.Timedelta(days=1)).strftime("%Y-%m-%d")
            print(f"ğŸ“¥ ä¸‹è¼‰ {index_type} å¢é‡è³‡æ–™ ({next_day} ~ {yesterday.date()})...")

            try:
                new_data = get_index_with_macd(
                    api,
                    index_type=index_type,
                    start=next_day,
                    end=yesterday.strftime("%Y-%m-%d"),
                )
                historical_df = pd.concat([cached_df, new_data])
                historical_df = historical_df[
                    ~historical_df.index.duplicated(keep="last")
                ]
                historical_df = historical_df.sort_index()
                historical_df = historical_df[historical_df.index.dayofweek < 5]
                historical_df = historical_df.dropna(
                    subset=["Open", "High", "Low", "Close"]
                )
                historical_df = _recalculate_all_indicators(historical_df)
            except Exception as e:
                print(f"âš ï¸ å¢é‡æ›´æ–°å¤±æ•—: {e}")
                historical_df = cached_df

        # ç”¨ FinLab æˆäº¤é‡‘é¡
        if finlab_amount is not None:
            amount_col = "TSE_Amount" if index_type == "TSE" else "OTC_Amount"
            common_dates = historical_df.index.intersection(finlab_amount.index)
            historical_df.loc[common_dates, "Amount"] = finlab_amount.loc[
                common_dates, amount_col
            ]

        _save_to_cache(historical_df, index_type)
    else:
        historical_df = cached_df
        if finlab_amount is not None:
            amount_col = "TSE_Amount" if index_type == "TSE" else "OTC_Amount"
            common_dates = historical_df.index.intersection(finlab_amount.index)
            historical_df.loc[common_dates, "Amount"] = finlab_amount.loc[
                common_dates, amount_col
            ]

    # å–å¾—ä»Šæ—¥å³æ™‚è³‡æ–™
    try:
        contract = (
            api.Contracts.Indexs.TSE.TSE001
            if index_type == "TSE"
            else api.Contracts.Indexs.OTC.OTC101
        )
        snapshot = api.snapshots([contract])[0]

        if today in historical_df.index:
            historical_df.loc[today, "Open"] = snapshot.open
            historical_df.loc[today, "High"] = max(
                historical_df.loc[today, "High"], snapshot.high
            )
            historical_df.loc[today, "Low"] = min(
                historical_df.loc[today, "Low"], snapshot.low
            )
            historical_df.loc[today, "Close"] = snapshot.close
            historical_df.loc[today, "Amount"] = snapshot.total_amount / 1e8
        else:
            today_data = pd.Series(
                {
                    "Open": snapshot.open,
                    "High": snapshot.high,
                    "Low": snapshot.low,
                    "Close": snapshot.close,
                    "Amount": snapshot.total_amount / 1e8,
                    "DIF": np.nan,
                    "MACD": np.nan,
                    "MACD_Hist": np.nan,
                    "ma5": np.nan,
                    "ma20": np.nan,
                    "ma60": np.nan,
                    "ma120": np.nan,
                },
                name=today,
            )
            historical_df = pd.concat([historical_df, today_data.to_frame().T])

        # åªé‡ç®—ä»Šå¤©çš„æŒ‡æ¨™
        historical_df = _recalculate_today_only(historical_df, today)

    except Exception as e:
        print(f"âš ï¸ å³æ™‚è³‡æ–™æ›´æ–°å¤±æ•—: {e}")

    historical_df = historical_df[historical_df.index.dayofweek < 5]
    return historical_df


def get_cached_or_fetch(api, force_refresh=False):
    """
    ğŸ†• å„ªåŒ–ç‰ˆï¼šæ›´è°æ˜çš„å¿«å–é‚è¼¯

    - æ­·å²è³‡æ–™ï¼šæ¯å°æ™‚æª¢æŸ¥ä¸€æ¬¡
    - å³æ™‚è³‡æ–™ï¼šæ¯ 60 ç§’æ›´æ–°ä¸€æ¬¡ï¼ˆéäº¤æ˜“æ™‚é–“ä¸æ›´æ–°ï¼‰
    - é é¢åˆ‡æ›æ™‚ï¼šç›´æ¥è¿”å›å¿«å–ï¼Œä¸é‡æ–°è¨ˆç®—
    """
    global _tse_cache, _otc_cache, _last_historical_update, _last_realtime_update

    now = datetime.now()
    current_time = now.time()

    # äº¤æ˜“æ™‚é–“åˆ¤æ–·
    trading_start = datetime.strptime("08:45", "%H:%M").time()
    trading_end = datetime.strptime("14:00", "%H:%M").time()
    is_trading_hours = trading_start <= current_time <= trading_end

    with _cache_lock:
        # ============================================
        # 1ï¸âƒ£ æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ­·å²è³‡æ–™ï¼ˆæ¯å°æ™‚ä¸€æ¬¡ï¼‰
        # ============================================
        need_historical = (
            _tse_cache is None
            or _otc_cache is None
            or force_refresh
            or _last_historical_update is None
            or (now - _last_historical_update).seconds > HISTORICAL_UPDATE_INTERVAL
        )

        if need_historical:
            print("=" * 50)
            print("ğŸ”„ æ›´æ–°æ­·å²è³‡æ–™...")
            start_time = time.time()

            _tse_cache = get_index_data_smart(api, "TSE", force_refresh=force_refresh)
            _otc_cache = get_index_data_smart(api, "OTC", force_refresh=force_refresh)
            _last_historical_update = now
            _last_realtime_update = now  # æ­·å²æ›´æ–°æ™‚ä¹Ÿæœƒæ›´æ–°å³æ™‚

            elapsed = time.time() - start_time
            print(f"âœ… æ­·å²è³‡æ–™æ›´æ–°å®Œæˆ! è€—æ™‚: {elapsed:.1f} ç§’")
            print("=" * 50)

            return _tse_cache.copy(), _otc_cache.copy()

        # ============================================
        # 2ï¸âƒ£ æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°å³æ™‚è³‡æ–™ï¼ˆæ¯åˆ†é˜ä¸€æ¬¡ï¼‰
        # ============================================
        need_realtime = (
            is_trading_hours
            and _last_realtime_update is not None
            and (now - _last_realtime_update).seconds > REALTIME_UPDATE_INTERVAL
        )

        if need_realtime:
            print(f"ğŸ“¡ æ›´æ–°å³æ™‚è³‡æ–™... ({now.strftime('%H:%M:%S')})")

            try:
                tse_contract = api.Contracts.Indexs.TSE.TSE001
                otc_contract = api.Contracts.Indexs.OTC.OTC101
                snapshots = api.snapshots([tse_contract, otc_contract])

                today = pd.Timestamp.now().normalize()

                # æ›´æ–° TSE
                tse_snap = snapshots[0]
                if today in _tse_cache.index:
                    _tse_cache.loc[today, "High"] = max(
                        _tse_cache.loc[today, "High"], tse_snap.high
                    )
                    _tse_cache.loc[today, "Low"] = min(
                        _tse_cache.loc[today, "Low"], tse_snap.low
                    )
                    _tse_cache.loc[today, "Close"] = tse_snap.close
                    _tse_cache.loc[today, "Amount"] = tse_snap.total_amount / 1e8
                _tse_cache = _recalculate_today_only(_tse_cache, today)

                # æ›´æ–° OTC
                otc_snap = snapshots[1]
                if today in _otc_cache.index:
                    _otc_cache.loc[today, "High"] = max(
                        _otc_cache.loc[today, "High"], otc_snap.high
                    )
                    _otc_cache.loc[today, "Low"] = min(
                        _otc_cache.loc[today, "Low"], otc_snap.low
                    )
                    _otc_cache.loc[today, "Close"] = otc_snap.close
                    _otc_cache.loc[today, "Amount"] = otc_snap.total_amount / 1e8
                _otc_cache = _recalculate_today_only(_otc_cache, today)

                _last_realtime_update = now
                print(
                    f"âœ… å³æ™‚æ›´æ–°å®Œæˆ - TSE: {tse_snap.close:.2f}, OTC: {otc_snap.close:.2f}"
                )

            except Exception as e:
                print(f"âš ï¸ å³æ™‚æ›´æ–°å¤±æ•—: {e}")

        # ============================================
        # 3ï¸âƒ£ ç›´æ¥è¿”å›å¿«å–ï¼ˆæœ€å¸¸è¦‹çš„æƒ…æ³ï¼‰
        # ============================================
        else:
            if not is_trading_hours:
                pass  # éäº¤æ˜“æ™‚é–“ï¼Œå®‰éœåœ°è¿”å›å¿«å–
            else:
                remaining = (
                    REALTIME_UPDATE_INTERVAL - (now - _last_realtime_update).seconds
                )
                # ä¸å° logï¼Œé¿å…åˆ·å±

        return _tse_cache.copy(), _otc_cache.copy()


def clear_cache():
    """æ¸…é™¤æ‰€æœ‰å¿«å–"""
    global _tse_cache, _otc_cache, _last_historical_update, _last_realtime_update

    with _cache_lock:
        _tse_cache = None
        _otc_cache = None
        _last_historical_update = None
        _last_realtime_update = None

    for cache_file in CACHE_DIR.glob("*.pkl"):
        try:
            cache_file.unlink()
            print(f"ğŸ—‘ï¸ å·²åˆªé™¤: {cache_file.name}")
        except Exception as e:
            print(f"âš ï¸ åˆªé™¤å¤±æ•—: {e}")

    print("âœ… å¿«å–å·²æ¸…é™¤")
